{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e7a0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from parser.parser import pcapsToCSVs\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch import nn\n",
    "\n",
    "from gnn.graph_transformer import GraphTransformer\n",
    "from graph_dataset.display_graph import displayGraph\n",
    "from graph_dataset.graph_dataset import (\n",
    "    loadGraphDataset,\n",
    "    oversampleInfrequentClasses,\n",
    "    randomizeGraphOrder,\n",
    ")\n",
    "from preprocessing.preprocessor import loadCSVsAndCreateGraphs\n",
    "from train_evaluate.train_evaluate import evaluate, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c0ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../../Datasets/TII-SSRC-23 Dataset/pcap/\"\n",
    "pcapsToCSVs(\n",
    "    dataset_path,\n",
    "    [\n",
    "        \"benign/audio/audio.pcap\",\n",
    "        \"benign/background/background.pcap\",\n",
    "        \"benign/text/text.pcap\",\n",
    "        \"benign/video/http.pcap\",\n",
    "        \"benign/video/rtp.pcap\",\n",
    "        \"benign/video/udp.pcap\",\n",
    "    ],\n",
    "    \"../../Datasets/TII-SSRC-23 Dataset/My Preprocessing/CSVs/Benign\",\n",
    "    5000000,\n",
    "    {\"Benign\": {}},\n",
    "    0,\n",
    ")\n",
    "\n",
    "pcapsToCSVs(\n",
    "    dataset_path,\n",
    "    [\n",
    "        \"malicious/bruteforce/bruteforce_dns.pcap\",\n",
    "        \"malicious/bruteforce/bruteforce_ftp.pcap\",\n",
    "        \"malicious/bruteforce/bruteforce_http.pcap\",\n",
    "        \"malicious/bruteforce/bruteforce_ssh.pcap\",\n",
    "        \"malicious/bruteforce/bruteforce_telnet.pcap\",\n",
    "    ],\n",
    "    \"../../Datasets/TII-SSRC-23 Dataset/My Preprocessing/CSVs/Malicious/Bruteforce\",\n",
    "    5000000,\n",
    "    {\"Bruteforce\": {}},\n",
    "    0,\n",
    ")\n",
    "pcapsToCSVs(\n",
    "    dataset_path,\n",
    "    [\n",
    "        \"malicious/dos/ack_tcp_dos.pcap\",\n",
    "        \"malicious/dos/cwr_tcp_dos.pcap\",\n",
    "        \"malicious/dos/ecn_tcp_dos.pcap\",\n",
    "        \"malicious/dos/http_dos.pcap\",\n",
    "        \"malicious/dos/icmp_dos.pcap\",\n",
    "        \"malicious/dos/mac_dos.pcap\",\n",
    "        \"malicious/dos/psh_tcp_dos.pcap\",\n",
    "        \"malicious/dos/rst_tcp_dos.pcap\",\n",
    "        \"malicious/dos/syn_tcp_dos.pcap\",\n",
    "        \"malicious/dos/udp_dos.pcap\",\n",
    "        \"malicious/dos/urg_tcp_dos.pcap\",\n",
    "        \"malicious/mirai-botnet/mirai_ddos_ack.pcap\",\n",
    "        \"malicious/mirai-botnet/mirai_ddos_dns.pcap\",\n",
    "        \"malicious/mirai-botnet/mirai_ddos_greeth.pcap\",\n",
    "        \"malicious/mirai-botnet/mirai_ddos_greip.pcap\",\n",
    "        \"malicious/mirai-botnet/mirai_ddos_http.pcap\",\n",
    "        \"malicious/mirai-botnet/mirai_ddos_syn.pcap\",\n",
    "        \"malicious/mirai-botnet/mirai_ddos_udp_udpplain.pcap\",\n",
    "    ],  # \"Attack traffic/DDoS ICMP Flood Attacks.pcap\" is not included because I only look at UDP and TCP packets\n",
    "    \"../../Datasets/TII-SSRC-23 Dataset/My Preprocessing/CSVs/Malicious/DOS\",\n",
    "    5000000,\n",
    "    {\"DOS\": {}},\n",
    "    0,\n",
    ")\n",
    "pcapsToCSVs(\n",
    "    dataset_path,\n",
    "    [\"malicious/information-gathering/information_gathering.pcap\"],\n",
    "    \"../../Datasets/TII-SSRC-23 Dataset/My Preprocessing/CSVs/Malicious/Information Gathering\",\n",
    "    5000000,\n",
    "    {\"Information Gathering\": {}},\n",
    "    0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8658ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 20\n",
    "csvs_paths = [\n",
    "    \"../../Datasets/TII-SSRC-23 Dataset/My Preprocessing/CSVs/Benign/\",\n",
    "    \"../../Datasets/TII-SSRC-23 Dataset/My Preprocessing/CSVs/Malicious/Bruteforce\",\n",
    "    \"../../Datasets/TII-SSRC-23 Dataset/My Preprocessing/CSVs/Malicious/DOS\",\n",
    "    \"../../Datasets/TII-SSRC-23 Dataset/My Preprocessing/CSVs/Malicious/Information Gathering\",\n",
    "]\n",
    "graphs_path = (\n",
    "    f\"../../Datasets/TII-SSRC-23 Dataset/My Preprocessing/Graphs/Size {num_nodes}/\"\n",
    ")\n",
    "loadCSVsAndCreateGraphs(csvs_paths, graphs_path, num_nodes, 10000, \"Generalized\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fd3443",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "number_nodes = 20\n",
    "epochs = 10\n",
    "batch_size = 512\n",
    "number_eigenvectors = 40 * 2\n",
    "embedding_size = 80 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bcc7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_mapping = {\n",
    "    \"Benign\": 1,\n",
    "    \"Bruteforce\": 2,\n",
    "    \"DOS\": 2,\n",
    "    \"Information Gathering\": 2,\n",
    "}\n",
    "true_labels = {\n",
    "    \"Benign\": 1,\n",
    "    \"Malicious\": 2,\n",
    "}\n",
    "graphs_path = (\n",
    "    f\"../../Datasets/TII-SSRC-23 Dataset/My Preprocessing/Graphs/Size {number_nodes}/\"\n",
    ")\n",
    "(graphs, labels) = loadGraphDataset(graphs_path, one_hot_mapping, 10)\n",
    "# displayGraph(graphs_train[0])\n",
    "\n",
    "n_splits = 10\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=101)\n",
    "current_split = 1\n",
    "\n",
    "attack_detection_best_model_params_path = os.path.join(\n",
    "    \"../../Checkpoints/\",\n",
    "    f\"tii-ssrc-23-binary-cv-{number_nodes}-{number_eigenvectors}-{embedding_size}.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a908c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train attack detection model\n",
    "print(\"Training attack detection model\")\n",
    "\n",
    "for train_idx, test_idx in kf.split(graphs, torch.argmax(labels, dim=1)):\n",
    "    evaluation_mode = {\n",
    "        \"mode\": \"cv\",\n",
    "        \"fold\": current_split,\n",
    "        \"name\": \"tii-ssrc-23-binary-cv\",\n",
    "    }\n",
    "\n",
    "    attack_detection_model = GraphTransformer(\n",
    "        number_nodes=number_nodes,\n",
    "        node_features_size=4,\n",
    "        number_eigenvectors=number_eigenvectors,\n",
    "        embedding_size=embedding_size,\n",
    "        feedforward_scaling=20 * 2,\n",
    "        num_heads=10 * 2,\n",
    "        num_layers=4,\n",
    "        dropout=0.5,\n",
    "        num_classes=2,\n",
    "        device=device,\n",
    "    ).to(device)\n",
    "\n",
    "    train_idx_list = train_idx.tolist()\n",
    "    test_idx_list = test_idx.tolist()\n",
    "    graphs_train = [graphs[i] for i in train_idx_list]\n",
    "    graphs_test = [graphs[i] for i in test_idx_list]\n",
    "    labels_train = labels[train_idx]\n",
    "    labels_test = labels[test_idx]\n",
    "\n",
    "    graphs_train, labels_train = oversampleInfrequentClasses(graphs_train, labels_train)\n",
    "    graphs_train = [g.to(device) for g in graphs_train]\n",
    "    graphs_test = [g.to(device) for g in graphs_test]\n",
    "    labels_train = labels_train.to(device)  # type: ignore\n",
    "    labels_test = labels_test.to(device)  # type: ignore\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(attack_detection_model.parameters(), lr=0.001)\n",
    "    best_train_loss = float(\"inf\")\n",
    "    train_loss = float(\"inf\")\n",
    "\n",
    "    for epoch_num in range(1, epochs + 1):\n",
    "        graphs_train, labels_train = randomizeGraphOrder(graphs_train, labels_train)\n",
    "        epoch_start_time = time.time()\n",
    "        # print(torch.cat((labels_train[:, :1], torch.flip(labels_train[:, :1], [1])), dim=1))\n",
    "        train_loss = train(\n",
    "            attack_detection_model,\n",
    "            loss_function,\n",
    "            optimizer,\n",
    "            graphs_train,\n",
    "            labels_train,\n",
    "            batch_size,\n",
    "            epoch_num,\n",
    "            device,\n",
    "            evaluation_mode,\n",
    "        )\n",
    "        elapsed = time.time() - epoch_start_time\n",
    "        print(\"-\" * 89)\n",
    "        print(\n",
    "            f\"| end of epoch {epoch_num:3d} | epoch last loss {train_loss} | time: {elapsed:5.2f}s\"\n",
    "        )\n",
    "        print(\"-\" * 89)\n",
    "\n",
    "        if train_loss < best_train_loss:\n",
    "            print(\"=\" * 89)\n",
    "            print(\"| Saving new best checkpoint\")\n",
    "            print(\"=\" * 89)\n",
    "            best_train_loss = train_loss\n",
    "            torch.save(\n",
    "                attack_detection_model.state_dict(),\n",
    "                attack_detection_best_model_params_path[:-3]\n",
    "                + f\"-fold-{current_split}.pt\",\n",
    "            )\n",
    "    print(\"=\" * 89)\n",
    "    print(\"| Saving final checkpoint\")\n",
    "    print(\"=\" * 89)\n",
    "    torch.save(\n",
    "        attack_detection_model.state_dict(),\n",
    "        attack_detection_best_model_params_path[:-3]\n",
    "        + f\"-fold-{current_split}-final.pt\",\n",
    "    )\n",
    "    results = evaluate(\n",
    "        attack_detection_model,\n",
    "        attack_detection_best_model_params_path[:-3] + f\"-fold-{current_split}.pt\",\n",
    "        loss_function,\n",
    "        graphs_test,\n",
    "        labels_test,\n",
    "        list(true_labels.keys()),\n",
    "        batch_size,\n",
    "        device,\n",
    "        evaluation_mode,\n",
    "    )\n",
    "    with open(\n",
    "        f\"Results/Pickle/tii-ssrc-23-binary-cv-fold-{current_split}-results.pkl\",\n",
    "        \"wb\",\n",
    "    ) as file:\n",
    "        pickle.dump(results, file)\n",
    "    current_split += 1\n",
    "\n",
    "# Show results\n",
    "results = []\n",
    "for i in range(0, n_splits):\n",
    "    with open(\n",
    "        f\"Results/Pickle/tii-ssrc-23-binary-cv-fold-{i+1}-results.pkl\", \"rb\"\n",
    "    ) as file:\n",
    "        results.append(pickle.load(file))\n",
    "    print(f\"Fold {i+1}\")\n",
    "    print(\"=\" * 89)\n",
    "    print(\n",
    "        f\"| accuracy: {results[i]['accuracy']} \"\n",
    "        f\"| macro precision: {results[i]['precision']}\\n\"\n",
    "        f\"| macro recall: {results[i]['recall']} \"\n",
    "        f\"| macro f1-score: {results[i]['f1_score']}\"\n",
    "    )\n",
    "    print(\"=\" * 89)\n",
    "    print(\"Classification Report\")\n",
    "    print(results[i][\"cr\"])\n",
    "    print(\"=\" * 89)\n",
    "\n",
    "\n",
    "print(\"=\" * 89)\n",
    "print(\"Mean Fold Metrics\")\n",
    "print(\"=\" * 89)\n",
    "print(\n",
    "    f\"| mean accuracy: {sum(results[i]['accuracy'] for i in range(0,n_splits)) / n_splits} \"\n",
    "    f\"| mean macro precision: {sum(results[i]['precision'] for i in range(0,n_splits)) / n_splits}\\n\"\n",
    "    f\"| mean macro recall: {sum(results[i]['recall'] for i in range(0, n_splits)) / n_splits} \"\n",
    "    f\"| mean macro f1-score: {sum(results[i]['f1_score'] for i in range(0, n_splits)) / n_splits}\"\n",
    ")\n",
    "print(\"=\" * 89)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
