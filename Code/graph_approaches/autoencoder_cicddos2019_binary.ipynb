{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa2a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "from parser.parser import pcapsToCSVs\n",
    "\n",
    "import torch\n",
    "from gnn.graph_transformer_autoencoder import (ClassifierDNN,\n",
    "                                               GraphTransformerAutoencoder)\n",
    "from graph_dataset.display_graph import displayGraph\n",
    "from graph_dataset.graph_dataset import (loadGraphDataset, randomizeGraphOrder,\n",
    "                                         splitGraphDataset)\n",
    "from preprocessing.preprocessor import loadCSVsAndCreateGraphs\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch import nn\n",
    "from train_evaluate.autoencoder_train_evaluate import (\n",
    "    autoencoder_dnn_evaluate, autoencoder_train, classifier_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b762b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the packets, many of the 'Attack times' in the paper are visibly incorrect\n",
    "# (eg. Training Set NTP contains LDAP packages?  Port 636 is LDAP, not NTP and this is\n",
    "# clearly script traffic, also SYNs are delayed 14:29 and after)\n",
    "# So I looked at the packets myself in order to verify the 'Attack times' I use below\n",
    "# These new 'Attack times' are more accurate than the dataset author's.\n",
    "# Also as seen in 'Labeling proof.ipynb', I prove that all attacks come from 172.16.0.5,\n",
    "# since that perfectly splits authors CSVs into benign and malicious packets\n",
    "# Also, I subtract 3 hours from the timestamps, since they are in UTC and the authors\n",
    "# seem to be in a UTC -3 timezone\n",
    "\n",
    "label_rules = {\n",
    "    \"NTP\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-12-01 10:17:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\"2018-12-01 12:00:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"UDP\"],\n",
    "        \"destination_port\": [1023],\n",
    "    },\n",
    "    \"DNS\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-12-01 10:17:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\"2018-12-01 12:00:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"UDP\"],\n",
    "        \"destination_port\": [53],\n",
    "    },\n",
    "    \"LDAP\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-12-01 10:17:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\"2018-12-01 12:00:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"UDP\"],\n",
    "        \"source_port\": [636],\n",
    "    },\n",
    "    \"MSSQL\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-12-01 10:17:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\"2018-12-01 12:00:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"UDP\"],\n",
    "        \"destination_port\": [1434],\n",
    "    },\n",
    "    \"NetBIOS\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-12-01 10:17:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\"2018-12-01 12:00:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"UDP\"],\n",
    "        \"destination_port\": [137],\n",
    "    },\n",
    "    \"SNMP\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-12-01 10:17:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\"2018-12-01 13:00:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"UDP\"],\n",
    "        \"source_port\": [161, 162],\n",
    "    },\n",
    "    \"SSDP\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-12-01 10:17:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\"2018-12-01 13:00:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"UDP\"],\n",
    "        \"source_port\": [2869, 5000],\n",
    "    },\n",
    "    \"UDP\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-12-01 12:45:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\"2018-12-01 13:09:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"UDP\"],\n",
    "    },\n",
    "    \"UDP-Lag\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-12-01 13:13:17\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\n",
    "            \"2018-12-01 13:26:00\", \"%Y-%m-%d %H:%M:%S\"\n",
    "        ),  # From 13:11 to 13:13 there are still UDP flood packets. From 13:15 to 13:26 the same attack patters are seen\n",
    "        \"protocol\": [\"UDP\"],\n",
    "    },\n",
    "    \"WebDDoS\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-12-01 13:18:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\"2018-12-01 14:29:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"TCP\"],\n",
    "        \"destination_port\": [80],\n",
    "    },\n",
    "    \"SYN\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-12-01 14:30:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\"2018-12-01 17:15:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"TCP\"],\n",
    "    },\n",
    "    \"TFTP\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\n",
    "            \"2018-12-01 14:40:00\", \"%Y-%m-%d %H:%M:%S\"\n",
    "        ),  # From 13:35:00 to 14:40:00, the packet sizes are off and no traffic on port 69 so I don't know what the packets are\n",
    "        \"end_time\": datetime.strptime(\"2018-12-01 17:15:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"UDP\"],\n",
    "    },\n",
    "    \"skip\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "    },\n",
    "    \"Benign\": {},\n",
    "}\n",
    "pcaps_path = \"../../Datasets/CIC-DDOS2019/PCAPs/01-12/PCAP-01-12/\"\n",
    "pcaps_name = \"SAT-01-12-2018_0\"\n",
    "pcaps_list = []\n",
    "for i in range(0, 818):\n",
    "    if i == 0:\n",
    "        pcaps_list.append(pcaps_name)\n",
    "    else:\n",
    "        pcaps_list.append(pcaps_name + str(i))\n",
    "pcapsToCSVs(\n",
    "    pcaps_path,\n",
    "    pcaps_list,\n",
    "    \"../../Datasets/CIC-DDOS2019/My Preprocessing/CSVs/01-12/\",\n",
    "    5000000,\n",
    "    label_rules,\n",
    "    3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8332f351",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_rules = {\n",
    "    \"PortMap\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-11-03 09:43:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\"2018-11-03 09:51:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"UDP\", \"TCP\"],\n",
    "    },\n",
    "    \"NetBIOS\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-11-03 10:00:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\"2018-11-03 10:09:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"UDP\"],\n",
    "        \"destination_port\": [137],\n",
    "    },\n",
    "    \"LDAP\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-11-03 10:21:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\"2018-11-03 10:30:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"UDP\"],\n",
    "        \"source_port\": [636],\n",
    "    },\n",
    "    \"MSSQL\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-11-03 10:33:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\"2018-11-03 10:42:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"UDP\"],\n",
    "        \"destination_port\": [1434],\n",
    "    },\n",
    "    \"UDP\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-11-03 10:53:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\"2018-11-03 11:03:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"UDP\"],\n",
    "    },\n",
    "    \"UDP-Lag\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-11-03 11:14:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\"2018-11-03 11:24:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"UDP\"],\n",
    "    },\n",
    "    \"SYN\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "        \"start_time\": datetime.strptime(\"2018-11-03 11:28:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"end_time\": datetime.strptime(\"2018-11-03 17:35:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"protocol\": [\"TCP\"],\n",
    "    },\n",
    "    \"skip\": {\n",
    "        \"ip\": [\"172.16.0.5\"],\n",
    "    },\n",
    "    \"Benign\": {},\n",
    "}\n",
    "pcaps_path = \"../../Datasets/CIC-DDOS2019/PCAPs/03-11/PCAP-03-11/\"\n",
    "pcaps_name = \"SAT-03-11-2018_0\"\n",
    "pcaps_list = []\n",
    "for i in range(0, 146):\n",
    "    if i == 0:\n",
    "        pcaps_list.append(pcaps_name)\n",
    "    else:\n",
    "        pcaps_list.append(pcaps_name + str(i))\n",
    "pcapsToCSVs(\n",
    "    pcaps_path,\n",
    "    pcaps_list,\n",
    "    \"../../Datasets/CIC-DDOS2019/My Preprocessing/CSVs/03-11/\",\n",
    "    5000000,\n",
    "    label_rules,\n",
    "    3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a384d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 20\n",
    "csvs_paths = [\n",
    "    \"../../Datasets/CIC-DDOS2019/My Preprocessing/CSVs/01-12/\",\n",
    "    \"../../Datasets/CIC-DDOS2019/My Preprocessing/CSVs/03-11/\",\n",
    "]\n",
    "graphs_path = f\"../../Datasets/CIC-DDOS2019/My Preprocessing/Graphs/Size {num_nodes}/\"\n",
    "loadCSVsAndCreateGraphs(csvs_paths, graphs_path, num_nodes, 10000, \"Endpoint\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1158aa2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "number_nodes = 20\n",
    "epochs = 3\n",
    "batch_size = 512\n",
    "number_eigenvectors = 40\n",
    "embedding_size = 80\n",
    "bottleneck_size = 20\n",
    "\n",
    "# Without the usage of the infrequent classes\n",
    "one_hot_mapping = {\n",
    "    \"Benign\": 1,\n",
    "    \"SYN\": 2,\n",
    "    \"TFTP\": 3,\n",
    "    \"UDP\": 4,\n",
    "    \"UDP-Lag\": 5,\n",
    "}\n",
    "\n",
    "graphs_path = (\n",
    "    f\"../../Datasets/CIC-DDOS2019/My Preprocessing/Graphs/Size {number_nodes}/\"\n",
    ")\n",
    "(graphs, labels) = loadGraphDataset(graphs_path, one_hot_mapping, 50)\n",
    "(\n",
    "    graphs_train,\n",
    "    graphs_dev,\n",
    "    graphs_test,\n",
    "    labels_train,\n",
    "    labels_dev,\n",
    "    labels_test,\n",
    ") = splitGraphDataset(graphs, labels, 0.1, 0.1, True, device)\n",
    "\n",
    "autoencoder_best_model_params_path = os.path.join(\n",
    "    \"../../Checkpoints/\",\n",
    "    f\"cicddos2019-binary-autoencoder-{number_nodes}-{number_eigenvectors}-{embedding_size}-{bottleneck_size}.pt\",\n",
    ")\n",
    "classifier_dnn_best_model_params_path = os.path.join(\n",
    "    \"../../Checkpoints/\",\n",
    "    \"cicddos2019-binary-classifier-dnn.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac30ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train autoencoder model\n",
    "print(\"Training DDoS detection model\")\n",
    "\n",
    "evaluation_mode = {\n",
    "    \"mode\": \"train-test-dev\",\n",
    "    \"set\": \"train\",\n",
    "    \"name\": \"cicddos2019-binary-autoencoder\",\n",
    "}\n",
    "\n",
    "graph_autoencoder_model = GraphTransformerAutoencoder(\n",
    "    number_nodes=number_nodes,\n",
    "    node_features_size=4,\n",
    "    number_eigenvectors=number_eigenvectors,\n",
    "    embedding_size=embedding_size,\n",
    "    feedforward_scaling=80,\n",
    "    num_heads=40,\n",
    "    num_layers=4,\n",
    "    dropout=0.5,\n",
    "    bottleneck_size=bottleneck_size,\n",
    "    device=device,\n",
    ").to(device)\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(graph_autoencoder_model.parameters(), lr=0.001)\n",
    "best_train_loss = float(\"inf\")\n",
    "train_loss = float(\"inf\")\n",
    "\n",
    "for epoch_num in range(1, epochs + 1):\n",
    "    graphs_train, labels_train = randomizeGraphOrder(graphs_train, labels_train)\n",
    "    epoch_start_time = time.time()\n",
    "    train_loss = autoencoder_train(\n",
    "        graph_autoencoder_model,\n",
    "        loss_function,\n",
    "        optimizer,\n",
    "        graphs_train,\n",
    "        batch_size,\n",
    "        epoch_num,\n",
    "        device,\n",
    "        evaluation_mode,\n",
    "    )\n",
    "    elapsed = time.time() - epoch_start_time\n",
    "    print(\"-\" * 89)\n",
    "    print(\n",
    "        f\"| end of epoch {epoch_num:3d} | epoch last loss {train_loss} | time: {elapsed:5.2f}s\"\n",
    "    )\n",
    "    print(\"-\" * 89)\n",
    "\n",
    "    if train_loss < best_train_loss:\n",
    "        print(\"=\" * 89)\n",
    "        print(\"| Saving new best checkpoint\")\n",
    "        print(\"=\" * 89)\n",
    "        best_train_loss = train_loss\n",
    "        torch.save(\n",
    "            graph_autoencoder_model.state_dict(),\n",
    "            autoencoder_best_model_params_path,\n",
    "        )\n",
    "print(\"=\" * 89)\n",
    "print(\"| Saving final checkpoint\")\n",
    "print(\"=\" * 89)\n",
    "torch.save(\n",
    "    graph_autoencoder_model.state_dict(),\n",
    "    autoencoder_best_model_params_path,\n",
    ")\n",
    "\n",
    "# Train classifier DNN model\n",
    "classifier_dnn_model = ClassifierDNN(\n",
    "    input_size=number_nodes * bottleneck_size,\n",
    "    num_classes=2,\n",
    "    dropout=0.5,\n",
    "    device=device,\n",
    ").to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier_dnn_model.parameters(), lr=0.001)\n",
    "best_train_loss = float(\"inf\")\n",
    "train_loss = float(\"inf\")\n",
    "\n",
    "for epoch_num in range(1, epochs + 1):\n",
    "    graphs_train, labels_train = randomizeGraphOrder(graphs_train, labels_train)\n",
    "    epoch_start_time = time.time()\n",
    "    train_loss = classifier_train(\n",
    "        classifier_dnn_model,\n",
    "        graph_autoencoder_model,\n",
    "        autoencoder_best_model_params_path,\n",
    "        loss_function,\n",
    "        optimizer,\n",
    "        graphs_train,\n",
    "        torch.cat((labels_train[:, :1], 1 - labels_train[:, :1]), dim=1),\n",
    "        batch_size,\n",
    "        epoch_num,\n",
    "        device,\n",
    "        evaluation_mode,\n",
    "    )\n",
    "    elapsed = time.time() - epoch_start_time\n",
    "    print(\"-\" * 89)\n",
    "    print(\n",
    "        f\"| end of epoch {epoch_num:3d} | epoch last loss {train_loss} | time: {elapsed:5.2f}s\"\n",
    "    )\n",
    "    print(\"-\" * 89)\n",
    "\n",
    "    if train_loss < best_train_loss:\n",
    "        print(\"=\" * 89)\n",
    "        print(\"| Saving checkpoint\")\n",
    "        print(\"=\" * 89)\n",
    "        best_train_loss = train_loss\n",
    "        torch.save(\n",
    "            classifier_dnn_model.state_dict(), classifier_dnn_best_model_params_path\n",
    "        )\n",
    "print(\"=\" * 89)\n",
    "print(\"| Saving final checkpoint\")\n",
    "print(\"=\" * 89)\n",
    "torch.save(\n",
    "    classifier_dnn_model.state_dict(),\n",
    "    classifier_dnn_best_model_params_path,\n",
    ")\n",
    "\n",
    "evaluation_mode[\"set\"] = \"dev\"\n",
    "print(\"Evaluating DDoS detection model with dev set\")\n",
    "results = autoencoder_dnn_evaluate(\n",
    "    graph_autoencoder_model,\n",
    "    classifier_dnn_model,\n",
    "    autoencoder_best_model_params_path,\n",
    "    classifier_dnn_best_model_params_path,\n",
    "    loss_function,\n",
    "    graphs_dev,\n",
    "    torch.cat((labels_dev[:, :1], 1 - labels_dev[:, :1]), dim=1),\n",
    "    [\"Benign\", \"Malicious\"],\n",
    "    batch_size,\n",
    "    device,\n",
    "    evaluation_mode,\n",
    ")\n",
    "with open(\n",
    "    \"Results/Pickle/cicddos2019-binary-autoencoder-results-dev.pkl\",\n",
    "    \"wb\",\n",
    ") as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "evaluation_mode[\"set\"] = \"test\"\n",
    "print(\"Evaluating DDoS detection model with test set\")\n",
    "results = autoencoder_dnn_evaluate(\n",
    "    graph_autoencoder_model,\n",
    "    classifier_dnn_model,\n",
    "    autoencoder_best_model_params_path,\n",
    "    classifier_dnn_best_model_params_path,\n",
    "    loss_function,\n",
    "    graphs_test,\n",
    "    torch.cat((labels_test[:, :1], 1 - labels_test[:, :1]), dim=1),\n",
    "    [\"Benign\", \"Malicious\"],\n",
    "    batch_size,\n",
    "    device,\n",
    "    evaluation_mode,\n",
    ")\n",
    "with open(\n",
    "    \"Results/Pickle/cicddos2019-binary-autoencoder-results-test.pkl\",\n",
    "    \"wb\",\n",
    ") as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "# Show dev set results\n",
    "print(\"=\" * 89)\n",
    "print(\"Dev set metrics\")\n",
    "print(\"=\" * 89)\n",
    "with open(\n",
    "    \"Results/Pickle/cicddos2019-binary-autoencoder-results-dev.pkl\", \"rb\"\n",
    ") as file:\n",
    "    results = pickle.load(file)\n",
    "print(\"=\" * 89)\n",
    "print(\n",
    "    f\"| accuracy: {results['accuracy']} \"\n",
    "    f\"| macro precision: {results['precision']}\\n\"\n",
    "    f\"| macro recall: {results['recall']} \"\n",
    "    f\"| macro f1-score: {results['f1_score']}\"\n",
    ")\n",
    "print(\"=\" * 89)\n",
    "print(\"Classification Report\")\n",
    "print(results[\"cr\"])\n",
    "print(\"=\" * 89)\n",
    "\n",
    "\n",
    "# Show test set results\n",
    "print(\"=\" * 89)\n",
    "print(\"Test set metrics\")\n",
    "print(\"=\" * 89)\n",
    "with open(\n",
    "    \"Results/Pickle/cicddos2019-binary-autoencoder-results-test.pkl\", \"rb\"\n",
    ") as file:\n",
    "    results = pickle.load(file)\n",
    "print(\n",
    "    f\"| accuracy: {results['accuracy']} \"\n",
    "    f\"| macro precision: {results['precision']}\\n\"\n",
    "    f\"| macro recall: {results['recall']} \"\n",
    "    f\"| macro f1-score: {results['f1_score']}\"\n",
    ")\n",
    "print(\"=\" * 89)\n",
    "print(\"Classification Report\")\n",
    "print(results[\"cr\"])\n",
    "print(\"=\" * 89)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
